<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>AnyThermal — Universal Thermal Perception Backbone</title>
  <meta name="description" content="AnyThermal: a universal thermal feature backbone distilled from RGB foundation models, plus the TartanRGBT platform and dataset.">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.36.1/gradio.js"></script>

  <style>
    .mia {
      font-family: monospace;
      font-weight: bold;
    }
  </style>
</head>

<body>

  <!-- NAVBAR -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow:1; justify-content:center;">
        <a class="navbar-item" href="#overview">Overview</a>
        <a class="navbar-item" href="#method">Method</a>
        <a class="navbar-item" href="#platform">Platform</a>
        <a class="navbar-item" href="#dataset">Dataset</a>
        <a class="navbar-item" href="#results">Results</a>
        <a class="navbar-item" href="#resources">Code & Data</a>
        <a class="navbar-item" href="#bibtex">BibTeX</a>
      </div>
    </div>
  </nav>

  <!-- HERO / OVERVIEW -->
  <section class="hero" id="overview">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              AnyThermal — Universal Thermal Perception Backbone
            </h1>
            <h3 class="is-size-5 has-text-weight-bold" style="color: orange;">
              Task-agnostic thermal feature learning for cross-modal place recognition, segmentation, and depth estimation.
            </h3>
            <br>

            <!-- Authors -->
            <div class="is-size-6 publication-authors">
              <span class="author-block"><a href="https://www.parvmaheshwari.com/" target="_blank">Parv Maheshwari*</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-people/jay-karhade/" target="_blank">Jay Karhade</a>,</span>
              <span class="author-block"><a href="http://yogesh-chawla.com/" target="_blank">Yogesh Chawla</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-people/isaiah-adu/" target="_blank">Isaiah Adu</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-people/florian-heisen/" target="_blank">Florian Heisen</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-people/andrew-porco/" target="_blank">Andrew Porco</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-people/andrew-jong/" target="_blank">Andrew Jong</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-people/yifei-liu/" target="_blank">Yifei Liu</a>,</span>
              <span class="author-block"><a href="https://bse.unl.edu/person/santosh-pitla/" target="_blank">Santosh Pitla</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/" target="_blank">Sebastian Scherer</a>,</span>
              <span class="author-block"><a href="https://www.ri.cmu.edu/ri-faculty/wenshan-wang/" target="_blank">Wenshan Wang</a></span>
            </div>

            <!-- Links -->
            <div class="publication-links">
              <span class="link-block">
                <a href="assets/AnyThermal.pdf" class="external-link button is-normal is-rounded is-dark" download>
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#results" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-chart-line"></i></span>
                  <span>Results</span>
                </a>
              </span>
            </div>

          </div>
        </div>

        <!-- Abstract -->
        <div class="columns is-centered" id="abstract">
          <div class="column is-two-thirds">
            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                We present <b>AnyThermal</b>, a task-agnostic thermal feature extraction backbone designed to provide strong generalization across diverse robotic perception tasks and environments.[file:1]
              </p>
              <p>
                AnyThermal is distilled from large-scale RGB foundation models (DINOv2) using synchronized RGB–thermal data collected from urban, indoor, aerial, and off-road domains.[file:1]
              </p>
              <p>
                To support this, we introduce the <b>TartanRGBT Platform</b>, an open-source hardware system for synchronized RGB–thermal data collection, and the <b>TartanRGBT Dataset</b>, a diverse multi-environment RGB–thermal dataset.[file:1][file:2]
              </p>
              <p>
                AnyThermal achieves state-of-the-art performance on cross-modal place recognition, thermal segmentation, and monocular thermal depth estimation, with improvements of up to 36% over existing baselines.[file:1][file:2]
              </p>
            </div>
          </div>
        </div>

      </div>
    </div>
  </section>


  <!-- KEY CONTRIBUTIONS -->
  <section class="section section-anchor" id="specs">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">Key Contributions</h2>
          <div class="content">
            <ul>
              <li><b>AnyThermal:</b> a DINOv2-based thermal encoder obtained via RGB–thermal knowledge distillation, usable as a drop-in backbone for multiple tasks.[file:1][file:2]</li>
              <li><b>Task-agnostic training:</b> contrastive distillation on CLS tokens across multiple RGB–T datasets spanning urban, indoor, aerial, and off-road environments.[file:1][file:2]</li>
              <li><b>Downstream performance:</b> state-of-the-art cross-modal place recognition, thermal segmentation, and monocular thermal depth estimation, outperforming comparable RGB-only backbones.[file:1]</li>
              <li><b>TartanRGBT platform:</b> first open-source synchronized stereo RGB–stereo thermal, IMU data collection rig built on NVIDIA Orin and FLIR Boson sensors.[file:1][file:2]</li>
              <li><b>TartanRGBT dataset:</b> a balanced, diverse RGB–T dataset across four environments (indoor, urban, parks, off-road) with registered, time-synced pairs.[file:1][file:2]</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

<!-- TEASER: GIF GRID -->
<section class="hero is-light section-anchor" id="teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-3">AnyThermal in Action</h2>
          <p class="subtitle is-6">
            AnyThermal performance across indoor, park, off-road, and urban environments.
          </p>

          <!-- 4 GIFs in a row -->
          <div class="columns is-multiline is-mobile">

            <div class="column is-one-quarter-desktop is-half-mobile">
              <img src="assets/indoor.gif" alt="Indoor results">
              <p class="is-size-7">Indoor</p>
            </div>

            <div class="column is-one-quarter-desktop is-half-mobile">
              <img src="assets/parks.gif" alt="Park results">
              <p class="is-size-7">Parks</p>
            </div>

            <div class="column is-one-quarter-desktop is-half-mobile">
              <img src="assets/offroad.gif" alt="Off-road results">
              <p class="is-size-7">Off-road</p>
            </div>

            <div class="column is-one-quarter-desktop is-half-mobile">
              <img src="assets/urban.gif" alt="Urban results">
              <p class="is-size-7">Urban</p>
            </div>

          </div>

          <p style="margin-top:0.75rem;">
            Thermal segmentation and cross-modal place recognition examples highlight the benefits over RGB-only backbones.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


  <!-- METHOD: ANYTHERMAL BACKBONE -->
  <section class="section section-anchor" id="method">
    <div class="container is-max-desktop">

      <h2 class="title is-3 has-text-centered">AnyThermal Backbone</h2>

      <div class="columns is-vcentered">
        <div class="column is-half">
          <h3 class="title is-4">RGB–Thermal Distillation</h3>
          <div class="content has-text-justified">
            <p>
              AnyThermal uses two ViT-B/14 DINOv2 encoders: a frozen RGB teacher and a trainable thermal student, both initialized with pre-trained RGB weights.[file:1]
            </p>
            <p>
              Thermal images are converted to three channels and passed through the student; a contrastive loss aligns the CLS-token embeddings of corresponding RGB–thermal pairs, encouraging shared global semantics while relaxing pixel-perfect alignment.[file:1]
            </p>
            <p>
              Distillation is performed across multiple RGB–T datasets, allowing the backbone to learn environment-agnostic thermal features that support diverse downstream heads.[file:1][file:2]
            </p>
          </div>
        </div>
        <div class="column is-half has-text-centered">
          <!-- Distillation diagram from paper (Fig. 2) -->
          <img src="assets/student_teacher.png" alt="AnyThermal distillation overview" style="max-width:100%;">
          <p class="is-size-7">
            Overview of RGB–thermal distillation and task-specific heads (VPR, segmentation, depth).[file:1]
          </p>
        </div>
      </div>

      <div class="columns">
        <div class="column">
          <h3 class="title is-4">Task Heads (Frozen Backbone)</h3>
          <div class="content">
            <ul>
              <li><b>Cross-modal Place Recognition:</b> SALAD head over AnyThermal features with triplet loss, retrieving RGB database images for thermal queries across indoor, aerial, and urban datasets.[file:1][file:2]</li>
              <li><b>Thermal Segmentation:</b> a lightweight two-layer MLP head over ViT patch embeddings, trained with Dice loss to segment MFNet thermal scenes in real time on Orin.[file:1]</li>
              <li><b>Mono-thermal Depth:</b> MiDaS-style encoder–decoder using multi-scale AnyThermal features, evaluated on MS2 with sparse LiDAR supervision.[file:1]</li>
            </ul>
          </div>
        </div>
      </div>

    </div>
  </section>

  <!-- PLATFORM: TARTANRGBT -->
  <section class="hero is-white section-anchor" id="platform">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">TartanRGBT Platform</h2>

        <div class="columns is-vcentered">
          <div class="column is-half has-text-centered">
            <!-- Platform CAD (Fig. 3) -->
            <img src="assets/tartanrgbt_setup.gif" alt="TartanRGBT platform CAD and wiring" style="max-width:100%;">
            <p class="is-size-7">
              CAD model and wiring overview of the handheld TartanRGBT platform.[file:1]
            </p>
          </div>
          <div class="column is-half">
            <div class="content">
              <p>
                The TartanRGBT platform is a handheld rig that captures synchronized stereo RGB, stereo thermal, and IMU at 30 Hz using a ZED X camera, two FLIR Boson 640+ thermal cameras, and an NVIDIA Jetson AGX Orin 64 GB computer.[file:1][file:2]
              </p>
              <p>
                All cameras are hardware-timed: the ZED X pair is factory-synced, and a trigger from the capture card synchronizes the thermal cameras via external sync pins in slave mode.[file:1]
              </p>
              <p>
                A custom 3D-printed enclosure with ergonomic handles, cooling fans, and exposed ports makes the system field-ready, while Docker-based auto-launch and a single recording button simplify operation.[file:1]
              </p>
            </div>
          </div>
        </div>

        <div class="columns">
          <div class="column">
            <h3 class="title is-4">Calibration & Registration</h3>
            <div class="content">
              <ul>
                <li>Thermal intrinsics are calibrated using a custom heated checkerboard, followed by fisheye rectification of thermal images.[file:1]</li>
                <li>Extrinsics between RGB and thermal cameras are derived from the CAD model, enabling 3D-aware alignment.[file:1]</li>
                <li>Registered RGB–thermal pairs are produced by estimating dense depth with FoundationStereo, transforming points into the thermal frame, and projecting with thermal intrinsics, with z-buffering and bilinear splatting to handle occlusions and sparsity.[file:1]</li>
              </ul>
            </div>
          </div>
        </div>

      </div>
    </div>
  </section>

  <!-- DATASET: TARTANRGBT -->
  <section class="section section-anchor" id="dataset">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">TartanRGBT Dataset</h2>

      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <p>
              The TartanRGBT dataset consists of 16,943 synchronized, registered RGB–thermal pairs sampled at 1 Hz for non-redundant distillation, covering indoor, urban driving, parks, and off-road environments.[file:1][file:2]
            </p>
            <p>
              Each sequence includes stereo RGB, stereo thermal, IMU, and thermal FFC status, enabling tasks such as cross-modal place recognition, segmentation, and RGB–thermal translation.[file:1]
            </p>
          </div>

          <h3 class="title is-4">Diversity Compared to Existing RGB–T Datasets</h3>
          <div class="table-container">
            <table class="table is-striped is-fullwidth is-hoverable">
              <thead>
                <tr>
                  <th>Dataset</th>
                  <th>Platform</th>
                  <th>RGB–T Pairs @1 Hz</th>
                  <th>Sync</th>
                  <th>Registered</th>
                  <th>Indoor</th>
                  <th>Off-road</th>
                  <th>Aerial</th>
                  <th>Urban Drive</th>
                  <th>Urban Park</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>MS2</td>
                  <td>Vehicle</td>
                  <td>16,215</td>
                  <td>Yes</td>
                  <td>No</td>
                  <td>No</td>
                  <td>No</td>
                  <td>No</td>
                  <td>Yes</td>
                  <td>No</td>
                </tr>
                <tr>
                  <td>ViVID++</td>
                  <td>Handheld/Vehicle</td>
                  <td>14,824</td>
                  <td>Mixed</td>
                  <td>No</td>
                  <td>Limited</td>
                  <td>No</td>
                  <td>Yes</td>
                  <td>Yes</td>
                  <td>No</td>
                </tr>
                <tr>
                  <td>CART</td>
                  <td>Handheld/Drone</td>
                  <td>9,678</td>
                  <td>Mixed</td>
                  <td>Yes</td>
                  <td>No</td>
                  <td>Yes</td>
                  <td>Yes</td>
                  <td>Yes</td>
                  <td>No</td>
                </tr>
                <tr>
                  <td>OdomBeyondVision</td>
                  <td>Drone/UGV/Handheld</td>
                  <td>7,129</td>
                  <td>Yes</td>
                  <td>No</td>
                  <td>Yes</td>
                  <td>No</td>
                  <td>No</td>
                  <td>No</td>
                  <td>No</td>
                </tr>
                <tr>
                  <td><b>TartanRGBT (Ours)</b></td>
                  <td>Handheld</td>
                  <td>16,943</td>
                  <td><b>Yes</b></td>
                  <td><b>Yes</b></td>
                  <td><b>Yes</b></td>
                  <td><b>Yes</b></td>
                  <td>No</td>
                  <td><b>Yes</b></td>
                  <td><b>Yes</b></td>
                </tr>
              </tbody>
            </table>
          </div>
          <p class="is-size-7">
            Summary of RGB–T datasets highlighting TartanRGBT’s breadth and synchronization/registration properties.[file:1]
          </p>

          <!-- Alignment visualization -->
          <div class="columns is-centered" style="margin-top:2rem;">
            <div class="column has-text-centered">
              <img src="assets/TartanRGBT_registration.png" alt="TartanRGBT RGB–thermal registration overlays" style="max-width:100%;">
              <p class="is-size-7">
                Alpha-blended RGB–thermal overlays across indoor, off-road, and urban domains, showing pixel-wise alignment.[file:1]
              </p>
            </div>
          </div>

        </div>
      </div>

    </div>
  </section>

  <!-- RESULTS -->
  <section class="hero is-light section-anchor" id="results">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Results Across Tasks</h2>

        <!-- Cross-modal Place Recognition -->
        <div class="columns">
          <div class="column">
            <h3 class="title is-4">Cross-Modal Place Recognition</h3>
            <div class="content">
              <p>
                AnyThermal with a SALAD head (AnyThermal-VPR) surpasses RGB-only and RGB–thermal baselines on MS2 (urban), CART (aerial), and OdomBeyondVision (indoor) in Recall@1.[file:1][file:2]
              </p>
              <div class="table-container">
                <table class="table is-bordered is-fullwidth is-narrow">
                  <thead>
                    <tr>
                      <th>Model</th>
                      <th>Backbone</th>
                      <th>Head</th>
                      <th>MS2 R@1</th>
                      <th>CART R@1</th>
                      <th>OBV R@1</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>DINOv2</td>
                      <td>DINOv2</td>
                      <td>CLS</td>
                      <td>27.21</td>
                      <td>25.98</td>
                      <td>29.49</td>
                    </tr>
                    <tr>
                      <td>SALAD</td>
                      <td>DINOv2</td>
                      <td>SALAD</td>
                      <td>76.97</td>
                      <td>49.38</td>
                      <td>38.94</td>
                    </tr>
                    <tr>
                      <td>ImageBind</td>
                      <td>ViT-H</td>
                      <td>CLS</td>
                      <td>0.79</td>
                      <td>1.13</td>
                      <td>10.25</td>
                    </tr>
                    <tr>
                      <td>SGM</td>
                      <td>ResNet-18</td>
                      <td>NetVLAD</td>
                      <td>20.02</td>
                      <td>45.59</td>
                      <td>21.05</td>
                    </tr>
                    <tr>
                      <td>AnyThermal</td>
                      <td>AnyThermal</td>
                      <td>CLS</td>
                      <td>75.39</td>
                      <td>45.45</td>
                      <td>45.40</td>
                    </tr>
                    <tr>
                      <td><b>AnyThermal-VPR</b></td>
                      <td>AnyThermal</td>
                      <td>SALAD</td>
                      <td><b>81.11</b></td>
                      <td><b>56.00</b></td>
                      <td><b>53.17</b></td>
                    </tr>
                  </tbody>
                </table>
              </div>
              <p class="is-size-7">
                Recall@1 across three datasets; AnyThermal-VPR delivers the best performance in all environments.[file:1]
              </p>
            </div>
          </div>
        </div>

        <!-- Segmentation & Depth -->
        <div class="columns">
          <div class="column">
            <h3 class="title is-4">Thermal Segmentation</h3>
            <div class="content">
              <p>
                On MFNet, AnyThermal with a two-layer MLP segmentation head achieves 53.47% mIoU and runs at 6.79 FPS on Orin, outperforming RTFFNet-152 and MCNet while being up to 3.6× faster than the closest competitor.[file:1]
              </p>
              <div class="table-container">
                <table class="table is-fullwidth is-narrow">
                  <thead>
                    <tr>
                      <th>Model</th>
                      <th>Params (M)</th>
                      <th>mIoU (%)</th>
                      <th>FPS (Orin)</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>RTFNet-152</td>
                      <td>196.37</td>
                      <td>47.00</td>
                      <td>8.37</td>
                    </tr>
                    <tr>
                      <td>MCNet</td>
                      <td>54.65</td>
                      <td>51.95</td>
                      <td>1.88</td>
                    </tr>
                    <tr>
                      <td>RGB DINO-SEG</td>
                      <td>87.02</td>
                      <td>45.46</td>
                      <td>6.79</td>
                    </tr>
                    <tr>
                      <td><b>AnyThermal-SEG</b></td>
                      <td>87.02</td>
                      <td><b>53.47</b></td>
                      <td>6.79</td>
                    </tr>
                  </tbody>
                </table>
              </div>
              <p class="is-size-7">
                AnyThermal improves both quality and efficiency for thermal semantic segmentation.[file:1]
              </p>
            </div>
          </div>

          <div class="column">
            <h3 class="title is-4">Mono-Thermal Depth Estimation</h3>
            <div class="content">
              <p>
                Plugging AnyThermal into MiDaS on MS2 yields lower AbsRel and RMSE than EfficientNet-Lite3 and RGB DINOv2 backbones.[file:1]
              </p>
              <div class="table-container">
                <table class="table is-fullwidth is-narrow">
                  <thead>
                    <tr>
                      <th>Backbone</th>
                      <th>AbsRel ↓</th>
                      <th>SqRel ↓</th>
                      <th>RMSE ↓</th>
                      <th>RMSElog ↓</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>EfficientNet-Lite3</td>
                      <td>0.1015</td>
                      <td>0.3955</td>
                      <td>2.9587</td>
                      <td>0.1417</td>
                    </tr>
                    <tr>
                      <td>DINOv2 ViT-B/14</td>
                      <td>0.0905</td>
                      <td>0.3177</td>
                      <td>2.7493</td>
                      <td>0.1208</td>
                    </tr>
                    <tr>
                      <td><b>AnyThermal</b></td>
                      <td><b>0.0883</b></td>
                      <td><b>0.3142</b></td>
                      <td><b>2.7432</b></td>
                      <td><b>0.1182</b></td>
                    </tr>
                  </tbody>
                </table>
              </div>
              <p class="is-size-7">
                AnyThermal consistently improves geometric prediction metrics without backbone fine-tuning.[file:1]
              </p>
            </div>
          </div>
        </div>

        <!-- Scaling & Diversity -->
        <div class="columns">
          <div class="column">
            <h3 class="title is-4">Scaling Data & Diversity</h3>
            <div class="content has-text-justified">
              <p>
                Ablations over pre-training datasets show that simply adding more urban sequences leads to saturation, whereas including TartanRGBT significantly boosts VPR, segmentation, and depth performance across domains.[file:1][file:2]
              </p>
              <p>
                The performance curves indicate that AnyThermal has not yet plateaued with current RGB–T data, suggesting further gains from broader, more diverse thermal datasets.[file:1]
              </p>
            </div>
            <!-- Optional: scaling plot from Fig. 8 -->
            <div class="has-text-centered">
              <img src="assets/thermal_segmentation.jpg" alt="Effect of pretraining datasets on downstream performance" style="max-width:100%;">
              <p class="is-size-7">
                Effect of adding Boson Nighttime (B), ViVID++ (V), Freiburg (F), STheReO (S), and TartanRGBT (T) on VPR, segmentation, and depth metrics.[file:1]
              </p>
            </div>
          </div>
        </div>

      </div>
    </div>
  </section>

  <!-- RESOURCES: CODE, DATA, CONTACT -->
  <section class="section section-anchor" id="resources">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Code, Data & Contact</h2>

      <div class="columns is-centered">
        <div class="column is-four-fifths has-text-centered">
          <div class="buttons is-centered">
            <a href="assets/AnyThermal.pdf" class="button is-rounded is-dark" download>
              <span class="icon"><i class="fas fa-file-pdf"></i></span>
              <span>Download Paper</span>
            </a>
            <a href="mailto:contact@anythermal.example" class="button is-rounded is-light">
              <span class="icon"><i class="fas fa-envelope"></i></span>
              <span>Contact</span>
            </a>
          </div>

          <div class="content has-text-justified" style="margin-top:1.5rem;">
            <p>
              Upon acceptance, we will release:
            </p>
            <ul>
              <li>Pre-trained AnyThermal backbones and task heads for VPR, segmentation, and depth.[file:1]</li>
              <li>CAD files, BOM, and software stack (Docker, sensor drivers, ROS2 launch) for the TartanRGBT platform.[file:1]</li>
              <li>The full TartanRGBT dataset with registered RGB–thermal pairs, dense depth, and odometry.[file:1][file:2]</li>
            </ul>
          </div>
        </div>
      </div>

    </div>
  </section>

  <!-- BIBTEX -->
  <section class="section section-anchor" id="bibtex">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">BibTeX</h2>
      <pre><code>@inproceedings{maheshwari2026anythermal,
  title     = {AnyThermal: Towards Learning Universal Representations for Thermal Perception},
  author    = {Maheshwari, Parv and Karhade, Jay and Chawla, Yogesh and Adu, Isaiah and
               Heisen, Florian and Porco, Andrew and Jong, Andrew and Liu, Yifei and
               Pitla, Santosh and Scherer, Sebastian and Wang, Wenshan},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2026}
}</code></pre>
    </div>
  </section>

  <!-- FOOTER -->
  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="assets/AnyThermal.pdf" download>
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="mailto:contact@anythermal.example">
          <i class="fas fa-envelope"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content has-text-centered">
            <p>
              © 2026 AnyThermal Project. All rights reserved.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- NAVBAR BURGER SCRIPT -->
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
      if ($navbarBurgers.length > 0) {
        $navbarBurgers.forEach(el => {
          el.addEventListener('click', () => {
            const target = el.dataset.target;
            const $target = document.getElementById(target);
            el.classList.toggle('is-active');
            $target.classList.toggle('is-active');
          });
        });
      }
    });
  </script>

</body>
</html>
